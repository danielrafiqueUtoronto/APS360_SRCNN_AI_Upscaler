{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"APS360_Project_SRGAN_Baseline.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1UJSMQVsScqzV63gj5ANPx3QFQlws5ykO","authorship_tag":"ABX9TyM2XADZ1TX07rgIlQMvC9/W"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"d71dcb02691948419e06550fff4159fc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ee6833e6e3d441ee985873601972976a","IPY_MODEL_b47689bf0d1b41bbb1f5c5fb5f84d318","IPY_MODEL_1ba9da10310b442b9b32fe169c9d6e6b"],"layout":"IPY_MODEL_f2342b9d0f3e421ba2d0a60fcecaee31"}},"ee6833e6e3d441ee985873601972976a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5e9ce6b466864c24a7db0c47ecb9e27c","placeholder":"​","style":"IPY_MODEL_31e52324ca0e4296be5ea097d347663f","value":"100%"}},"b47689bf0d1b41bbb1f5c5fb5f84d318":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_22fcb7e9524341358829ad53664bb35a","max":574673361,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2ab972cca66d475cb17332fd8a974af3","value":574673361}},"1ba9da10310b442b9b32fe169c9d6e6b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb207f252f884f7c88f20a642177cdd6","placeholder":"​","style":"IPY_MODEL_b5b06ef308564df98867afbde3d7a114","value":" 548M/548M [00:10&lt;00:00, 64.3MB/s]"}},"f2342b9d0f3e421ba2d0a60fcecaee31":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e9ce6b466864c24a7db0c47ecb9e27c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31e52324ca0e4296be5ea097d347663f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"22fcb7e9524341358829ad53664bb35a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ab972cca66d475cb17332fd8a974af3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"eb207f252f884f7c88f20a642177cdd6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5b06ef308564df98867afbde3d7a114":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["This Baseline SRGAN Model was implemented for benchmarking purposes and is referenced by the following implementation: \n","https://github.com/aladdinpersson/Machine-Learning-Collection/tree/master/ML/Pytorch/GANs/SRGAN "],"metadata":{"id":"d4_UU7NPNSVg"}},{"cell_type":"code","source":["import os\n","import torch\n","import torch.nn as n\n","import torch.nn.functional as f\n","import numpy as np\n","import os\n","from torchsummary import summary\n","import torch.optim as optim\n","from tqdm import tqdm\n","from torchvision import models\n","import cv2\n","from matplotlib import pyplot as plt\n","from PIL import Image"],"metadata":{"id":"8D4hqBPwdfOV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Baseline will Convert any image up to 4x scale"],"metadata":{"id":"mjJQAXcEeCbF"}},{"cell_type":"code","source":["import torch\n","from torch import nn\n","\n","\n","class ConvBlock(nn.Module):\n","    def __init__(\n","        self,\n","        in_channels,\n","        out_channels,\n","        discriminator=False,\n","        use_act=True,\n","        use_bn=True,\n","        **kwargs,\n","    ):\n","        super().__init__()\n","        self.use_act = use_act\n","        self.cnn = nn.Conv2d(in_channels, out_channels, **kwargs, bias=not use_bn)\n","        self.bn = nn.BatchNorm2d(out_channels) if use_bn else nn.Identity()\n","        self.act = (\n","            nn.LeakyReLU(0.2, inplace=True)\n","            if discriminator\n","            else nn.PReLU(num_parameters=out_channels)\n","        )\n","\n","    def forward(self, x):\n","        return self.act(self.bn(self.cnn(x))) if self.use_act else self.bn(self.cnn(x))\n","\n","\n","class UpsampleBlock(nn.Module):\n","    def __init__(self, in_c, scale_factor):\n","        super().__init__()\n","        self.conv = nn.Conv2d(in_c, in_c * scale_factor ** 2, 3, 1, 1)\n","        self.ps = nn.PixelShuffle(scale_factor)  # in_c * 4, H, W --> in_c, H*2, W*2\n","        self.act = nn.PReLU(num_parameters=in_c)\n","\n","    def forward(self, x):\n","        return self.act(self.ps(self.conv(x)))\n","\n","\n","class ResidualBlock(nn.Module):\n","    def __init__(self, in_channels):\n","        super().__init__()\n","        self.block1 = ConvBlock(\n","            in_channels,\n","            in_channels,\n","            kernel_size=3,\n","            stride=1,\n","            padding=1\n","        )\n","        self.block2 = ConvBlock(\n","            in_channels,\n","            in_channels,\n","            kernel_size=3,\n","            stride=1,\n","            padding=1,\n","            use_act=False,\n","        )\n","\n","    def forward(self, x):\n","        out = self.block1(x)\n","        out = self.block2(out)\n","        return out + x\n","\n","\n","class Generator(nn.Module):\n","    def __init__(self, in_channels=3, num_channels=64, num_blocks=16):\n","        super().__init__()\n","        self.initial = ConvBlock(in_channels, num_channels, kernel_size=9, stride=1, padding=4, use_bn=False)\n","        self.residuals = nn.Sequential(*[ResidualBlock(num_channels) for _ in range(num_blocks)])\n","        self.convblock = ConvBlock(num_channels, num_channels, kernel_size=3, stride=1, padding=1, use_act=False)\n","        self.upsamples = nn.Sequential(UpsampleBlock(num_channels, 2), UpsampleBlock(num_channels, 2))\n","        self.final = nn.Conv2d(num_channels, in_channels, kernel_size=9, stride=1, padding=4)\n","\n","    def forward(self, x):\n","        initial = self.initial(x)\n","        x = self.residuals(initial)\n","        x = self.convblock(x) + initial\n","        x = self.upsamples(x)\n","        return torch.tanh(self.final(x))\n","\n","\n","class Discriminator(nn.Module):\n","    def __init__(self, in_channels=3, features=[64, 64, 128, 128, 256, 256, 512, 512]):\n","        super().__init__()\n","        blocks = []\n","        for idx, feature in enumerate(features):\n","            blocks.append(\n","                ConvBlock(\n","                    in_channels,\n","                    feature,\n","                    kernel_size=3,\n","                    stride=1 + idx % 2,\n","                    padding=1,\n","                    discriminator=True,\n","                    use_act=True,\n","                    use_bn=False if idx == 0 else True,\n","                )\n","            )\n","            in_channels = feature\n","\n","        self.blocks = nn.Sequential(*blocks)\n","        self.classifier = nn.Sequential(\n","            nn.AdaptiveAvgPool2d((6, 6)),\n","            nn.Flatten(),\n","            nn.Linear(512*6*6, 1024),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Linear(1024, 1),\n","        )\n","\n","    def forward(self, x):\n","        x = self.blocks(x)\n","        return self.classifier(x)\n","\n","def test():\n","    low_resolution = 24  # 96x96 -> 24x24\n","    with torch.cuda.amp.autocast():\n","        x = torch.randn((5, 3, low_resolution, low_resolution))\n","        gen = Generator()\n","        gen_out = gen(x)\n","        disc = Discriminator()\n","        disc_out = disc(gen_out)\n","\n","        print(gen_out.shape)\n","        print(disc_out.shape)\n","\n","\n","if __name__ == \"__main__\":\n","    test()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OPUgjtGLnVNV","executionInfo":{"status":"ok","timestamp":1649095282935,"user_tz":240,"elapsed":1828,"user":{"displayName":"Daniel Rafique","userId":"02654504376856222239"}},"outputId":"34c05868-22d6-4754-9e82-1c96c76e923e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([5, 3, 96, 96])\n","torch.Size([5, 1])\n"]}]},{"cell_type":"code","source":["!pip install albumentations==0.4.6\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WnWkZnvltuEY","executionInfo":{"status":"ok","timestamp":1649095328358,"user_tz":240,"elapsed":8238,"user":{"displayName":"Daniel Rafique","userId":"02654504376856222239"}},"outputId":"98a0c38d-8f2c-4fd1-ab31-f3e1fa1025de"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting albumentations==0.4.6\n","  Downloading albumentations-0.4.6.tar.gz (117 kB)\n","\u001b[K     |████████████████████████████████| 117 kB 7.0 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (1.21.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (1.4.1)\n","Collecting imgaug>=0.4.0\n","  Downloading imgaug-0.4.0-py2.py3-none-any.whl (948 kB)\n","\u001b[K     |████████████████████████████████| 948 kB 41.5 MB/s \n","\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (3.13)\n","Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (4.1.2.30)\n","Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (0.18.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.15.0)\n","Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.8.1.post1)\n","Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (2.4.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (3.2.2)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (7.1.2)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (1.3.0)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2.6.3)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2021.11.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (1.4.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (0.11.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (2.8.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (3.0.7)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (3.10.0.2)\n","Building wheels for collected packages: albumentations\n","  Building wheel for albumentations (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for albumentations: filename=albumentations-0.4.6-py3-none-any.whl size=65174 sha256=214733884647ad782c55d44f46f3c39e1f9de82be86d84f4b9faa84ee7488c1b\n","  Stored in directory: /root/.cache/pip/wheels/cf/34/0f/cb2a5f93561a181a4bcc84847ad6aaceea8b5a3127469616cc\n","Successfully built albumentations\n","Installing collected packages: imgaug, albumentations\n","  Attempting uninstall: imgaug\n","    Found existing installation: imgaug 0.2.9\n","    Uninstalling imgaug-0.2.9:\n","      Successfully uninstalled imgaug-0.2.9\n","  Attempting uninstall: albumentations\n","    Found existing installation: albumentations 0.1.12\n","    Uninstalling albumentations-0.1.12:\n","      Successfully uninstalled albumentations-0.1.12\n","Successfully installed albumentations-0.4.6 imgaug-0.4.0\n"]}]},{"cell_type":"code","source":["from PIL import Image\n","LOAD_MODEL = True\n","SAVE_MODEL = True\n","CHECKPOINT_GEN = \"gen.pth.tar\"\n","CHECKPOINT_DISC = \"disc.pth.tar\"\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","LEARNING_RATE = 1e-4\n","NUM_EPOCHS = 50\n","BATCH_SIZE = 16\n","NUM_WORKERS = 4\n","HIGH_RES = 224\n","LOW_RES = HIGH_RES // 4\n","IMG_CHANNELS = 3\n","\n","highres_transform = A.Compose(\n","    [\n","        A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n","        ToTensorV2(),\n","    ]\n",")\n","\n","lowres_transform = A.Compose(\n","    [\n","        A.Resize(width=LOW_RES, height=LOW_RES, interpolation=Image.BICUBIC),\n","        A.Normalize(mean=[0, 0, 0], std=[1, 1, 1]),\n","        ToTensorV2(),\n","    ]\n",")\n","\n","both_transforms = A.Compose(\n","    [\n","        A.RandomCrop(width=HIGH_RES, height=HIGH_RES),\n","        A.HorizontalFlip(p=0.5),\n","        A.RandomRotate90(p=0.5),\n","    ]\n",")\n","\n","test_transform = A.Compose(\n","    [\n","        A.Normalize(mean=[0, 0, 0], std=[1, 1, 1]),\n","        ToTensorV2(),\n","    ]\n",")"],"metadata":{"id":"65l9d3a4sqIX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch.nn as nn\n","from torchvision.models import vgg19\n","\n","# phi_5,4 5th conv layer before maxpooling but after activation\n","\n","class VGGLoss(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.vgg = vgg19(pretrained=True).features[:36].eval().to(DEVICE)\n","        self.loss = nn.MSELoss()\n","\n","        for param in self.vgg.parameters():\n","            param.requires_grad = False\n","\n","    def forward(self, input, target):\n","        vgg_input_features = self.vgg(input)\n","        vgg_target_features = self.vgg(target)\n","        return self.loss(vgg_input_features, vgg_target_features)\n"],"metadata":{"id":"I_AzLUo2rgJA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import numpy as np\n","from torch.utils.data import Dataset, DataLoader\n","from PIL import Image\n","\n","\n","class MyImageFolder(Dataset):\n","    def __init__(self, root_dir):\n","        super(MyImageFolder, self).__init__()\n","        self.data = []\n","        self.root_dir = root_dir\n","        self.class_names = os.listdir(root_dir)\n","\n","        for index, name in enumerate(self.class_names):\n","            files = os.listdir(os.path.join(root_dir, name))\n","            self.data += list(zip(files, [index] * len(files)))\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","        img_file, label = self.data[index]\n","        root_and_dir = os.path.join(self.root_dir, self.class_names[label])\n","\n","        image = np.array(Image.open(os.path.join(root_and_dir, img_file)))\n","        image = both_transforms(image=image)[\"image\"]\n","        high_res = highres_transform(image=image)[\"image\"]\n","        low_res = lowres_transform(image=image)[\"image\"]\n","        return low_res, high_res\n","\n","\n","def test():\n","    dataset = MyImageFolder(root_dir=\"/content/drive/MyDrive/APS360/Bird_Data_HR/\")\n","    \n","    loader = DataLoader(dataset, batch_size=1, num_workers=8)\n","\n","    print(len(dataset))\n","    #for low_res, high_res in loader:\n","        #print(low_res.shape)\n","        #print(high_res.shape)\n","\n","\n","if __name__ == \"__main__\":\n","    test()"],"metadata":{"id":"P1kLZGaS7hPO","executionInfo":{"status":"ok","timestamp":1649095353620,"user_tz":240,"elapsed":12619,"user":{"displayName":"Daniel Rafique","userId":"02654504376856222239"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"56173116-e739-45c8-b4ad-69bad67a5920"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]}]},{"cell_type":"code","source":["import numpy as np\n","from PIL import Image\n","from torchvision.utils import save_image\n","\n","\n","def gradient_penalty(critic, real, fake, device):\n","    BATCH_SIZE, C, H, W = real.shape\n","    alpha = torch.rand((BATCH_SIZE, 1, 1, 1)).repeat(1, C, H, W).to(device)\n","    interpolated_images = real * alpha + fake.detach() * (1 - alpha)\n","    interpolated_images.requires_grad_(True)\n","\n","    # Calculate critic scores\n","    mixed_scores = critic(interpolated_images)\n","\n","    # Take the gradient of the scores with respect to the images\n","    gradient = torch.autograd.grad(\n","        inputs=interpolated_images,\n","        outputs=mixed_scores,\n","        grad_outputs=torch.ones_like(mixed_scores),\n","        create_graph=True,\n","        retain_graph=True,\n","    )[0]\n","    gradient = gradient.view(gradient.shape[0], -1)\n","    gradient_norm = gradient.norm(2, dim=1)\n","    gradient_penalty = torch.mean((gradient_norm - 1) ** 2)\n","    return gradient_penalty\n","\n","\n","def save_checkpoint(model, optimizer, filename=\"my_checkpoint.pth.tar\"):\n","    print(\"=> Saving checkpoint\")\n","    checkpoint = {\n","        \"state_dict\": model.state_dict(),\n","        \"optimizer\": optimizer.state_dict(),\n","    }\n","    torch.save(checkpoint, filename)\n","\n","\n","def load_checkpoint(checkpoint_file, model, optimizer, lr):\n","    print(\"=> Loading checkpoint\")\n","    checkpoint = torch.load(checkpoint_file, map_location=DEVICE)\n","    model.load_state_dict(checkpoint[\"state_dict\"])\n","    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n","\n","    # If we don't do this then it will just have learning rate of old checkpoint\n","    # and it will lead to many hours of debugging \\:\n","    for param_group in optimizer.param_groups:\n","        param_group[\"lr\"] = lr\n","\n","\n","def plot_examples(low_res_folder, gen):\n","    files = os.listdir(low_res_folder)\n","\n","    gen.eval()\n","    for file in files:\n","      if file!= '.ipynb_checkpoints':\n","        #image = Image.open(\"/content/drive/MyDrive/APS360/Bird_Data_LR_Test/\" + file)\n","        #image = Image.open(\"/content/test_images/\" + file)\n","        image = Image.open(\"/content/drive/MyDrive/APS360/personal_bird_test_images/bird_pic224/pics/\" + file)\n","        #image = Image.open(low_res_folder)\n","        with torch.no_grad():\n","            upscaled_img = gen(\n","                test_transform(image=np.asarray(image))[\"image\"]\n","                .unsqueeze(0)\n","                .to(DEVICE)\n","            )\n","        save_image(upscaled_img * 0.5 + 0.5, f\"saved/{file}\")\n","    gen.train()"],"metadata":{"id":"V7vOzP3f8dla"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from torch import optim\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","\n","torch.backends.cudnn.benchmark = True\n","\n","def test_fn(loader, disc, gen, opt_gen, opt_disc, mse, bce, vgg_loss):\n","  loop = tqdm(loader, leave=True)\n","  for idx, (low_res, high_res) in enumerate(loop):\n","    high_res = high_res.to(DEVICE)\n","    low_res = low_res.to(DEVICE)\n","    fake = gen(low_res)\n","    loss = mse(fake, high_res)\n","  \n","  return loss\n","\n","def train_fn(loader, disc, gen, opt_gen, opt_disc, mse, bce, vgg_loss):\n","    loop = tqdm(loader, leave=True)\n","    for idx, (low_res, high_res) in enumerate(loop):\n","        high_res = high_res.to(DEVICE)\n","        low_res = low_res.to(DEVICE)\n","        \n","        ### Train Discriminator: max log(D(x)) + log(1 - D(G(z)))\n","        fake = gen(low_res)\n","        disc_real = disc(high_res)\n","        disc_fake = disc(fake.detach())\n","        disc_loss_real = bce(\n","            disc_real, torch.ones_like(disc_real) - 0.1 * torch.rand_like(disc_real)\n","        )\n","        disc_loss_fake = bce(disc_fake, torch.zeros_like(disc_fake))\n","        loss_disc = disc_loss_fake + disc_loss_real\n","\n","        opt_disc.zero_grad()\n","        loss_disc.backward()\n","        opt_disc.step()\n","\n","        # Train Generator: min log(1 - D(G(z))) <-> max log(D(G(z))\n","        disc_fake = disc(fake)\n","        l2_loss = mse(fake, high_res)\n","        adversarial_loss = 1e-3 * bce(disc_fake, torch.ones_like(disc_fake))\n","        loss_for_vgg = 0.006 * vgg_loss(fake, high_res)\n","        gen_loss = l2_loss + loss_for_vgg + adversarial_loss\n","\n","        opt_gen.zero_grad()\n","        gen_loss.backward()\n","        opt_gen.step()\n","\n","        if idx % 200 == 0:\n","            #plot_examples(\"test_images/\", gen)\n","            print(f'gen loss = {gen_loss}')\n","            #print(f'disc loss = {loss_disc}')\n","\n","    return l2_loss\n","\n","def main():\n","    train_dataset = MyImageFolder(root_dir=\"/content/drive/MyDrive/APS360/Bird_Data_HR_Train\")\n","    test_dataset = MyImageFolder(root_dir = \"/content/drive/MyDrive/APS360/Bird_Data_HR_Test\")\n","    train_loader = DataLoader(\n","        train_dataset,\n","        batch_size=BATCH_SIZE,\n","        shuffle=True,\n","        pin_memory=True,\n","        num_workers=NUM_WORKERS,\n","    )\n","\n","    test_loader = DataLoader(\n","        test_dataset,\n","        batch_size=BATCH_SIZE,\n","        shuffle=True,\n","        pin_memory=True,\n","        num_workers=NUM_WORKERS,\n","    )\n","    gen = Generator(in_channels=3).to(DEVICE)\n","    disc = Discriminator(in_channels=3).to(DEVICE)\n","    opt_gen = optim.Adam(gen.parameters(), lr=LEARNING_RATE, betas=(0.9, 0.999))\n","    opt_disc = optim.Adam(disc.parameters(), lr=LEARNING_RATE, betas=(0.9, 0.999))\n","    mse = nn.MSELoss()\n","    bce = nn.BCEWithLogitsLoss()\n","    vgg_loss = VGGLoss()\n","\n","    if LOAD_MODEL:\n","        load_checkpoint(\n","            CHECKPOINT_GEN,\n","            gen,\n","            opt_gen,\n","            LEARNING_RATE,\n","        )\n","        load_checkpoint(\n","           CHECKPOINT_DISC, disc, opt_disc, LEARNING_RATE,\n","        )\n","    train_loss =  []\n","    test_loss = []\n","    for epoch in range(NUM_EPOCHS):\n","        print(f'epoch: {epoch}')\n","        trLoss = train_fn(train_loader, disc, gen, opt_gen, opt_disc, mse, bce, vgg_loss)\n","        testLoss = test_fn(test_loader, disc, gen, opt_gen, opt_disc, mse, bce, vgg_loss)\n","        train_loss.append(trLoss)\n","        test_loss.append(test_loss)\n","\n","        if SAVE_MODEL:\n","            save_checkpoint(gen, opt_gen, filename=CHECKPOINT_GEN)\n","            save_checkpoint(disc, opt_disc, filename=CHECKPOINT_DISC)\n","    print(train_loss)\n","    print('test loss')\n","    print(test_loss)\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pShLaFO16izQ","outputId":"cb9460d3-cf95-4577-f9a2-8447e97479a2","executionInfo":{"status":"ok","timestamp":1648789765820,"user_tz":240,"elapsed":4158800,"user":{"displayName":"Daniel Rafique","userId":"02654504376856222239"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 0\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/88 [00:02<02:56,  2.02s/it]"]},{"output_type":"stream","name":"stdout","text":["gen loss = 0.21800506114959717\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 88/88 [01:20<00:00,  1.10it/s]\n","100%|██████████| 38/38 [00:03<00:00, 11.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","=> Saving checkpoint\n","epoch: 1\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/88 [00:01<01:53,  1.30s/it]"]},{"output_type":"stream","name":"stdout","text":["gen loss = 0.03961951658129692\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 88/88 [01:19<00:00,  1.11it/s]\n","100%|██████████| 38/38 [00:03<00:00, 11.22it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","=> Saving checkpoint\n","epoch: 2\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/88 [00:01<02:09,  1.49s/it]"]},{"output_type":"stream","name":"stdout","text":["gen loss = 0.041331686079502106\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 88/88 [01:18<00:00,  1.12it/s]\n","100%|██████████| 38/38 [00:03<00:00, 11.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","=> Saving checkpoint\n","epoch: 3\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/88 [00:01<02:04,  1.43s/it]"]},{"output_type":"stream","name":"stdout","text":["gen loss = 0.03974296152591705\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 88/88 [01:18<00:00,  1.12it/s]\n","100%|██████████| 38/38 [00:03<00:00, 11.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","=> Saving checkpoint\n","epoch: 4\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/88 [00:01<02:04,  1.43s/it]"]},{"output_type":"stream","name":"stdout","text":["gen loss = 0.0457458533346653\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 88/88 [01:18<00:00,  1.12it/s]\n","100%|██████████| 38/38 [00:03<00:00, 10.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","=> Saving checkpoint\n","epoch: 5\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/88 [00:01<01:59,  1.38s/it]"]},{"output_type":"stream","name":"stdout","text":["gen loss = 0.03304334729909897\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 88/88 [01:18<00:00,  1.12it/s]\n","100%|██████████| 38/38 [00:03<00:00, 11.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","=> Saving checkpoint\n","epoch: 6\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/88 [00:01<02:08,  1.48s/it]"]},{"output_type":"stream","name":"stdout","text":["gen loss = 0.03339751064777374\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 88/88 [01:18<00:00,  1.11it/s]\n","100%|██████████| 38/38 [00:03<00:00, 11.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","=> Saving checkpoint\n","epoch: 7\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/88 [00:01<01:56,  1.34s/it]"]},{"output_type":"stream","name":"stdout","text":["gen loss = 0.029273053631186485\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 88/88 [01:18<00:00,  1.12it/s]\n","100%|██████████| 38/38 [00:03<00:00, 11.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","=> Saving checkpoint\n","epoch: 8\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/88 [00:01<02:05,  1.45s/it]"]},{"output_type":"stream","name":"stdout","text":["gen loss = 0.033955760300159454\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 88/88 [01:18<00:00,  1.11it/s]\n","100%|██████████| 38/38 [00:03<00:00, 11.00it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","=> Saving checkpoint\n","epoch: 9\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/88 [00:01<02:04,  1.43s/it]"]},{"output_type":"stream","name":"stdout","text":["gen loss = 0.031550176441669464\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 88/88 [01:18<00:00,  1.12it/s]\n","100%|██████████| 38/38 [00:03<00:00, 11.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","=> Saving checkpoint\n","epoch: 10\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/88 [00:01<02:06,  1.46s/it]"]},{"output_type":"stream","name":"stdout","text":["gen loss = 0.04448777809739113\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 88/88 [01:18<00:00,  1.11it/s]\n","100%|██████████| 38/38 [00:03<00:00, 11.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","=> Saving checkpoint\n","epoch: 11\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/88 [00:01<01:55,  1.33s/it]"]},{"output_type":"stream","name":"stdout","text":["gen loss = 0.04125586152076721\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 88/88 [01:18<00:00,  1.12it/s]\n","100%|██████████| 38/38 [00:03<00:00, 11.22it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","=> Saving checkpoint\n","epoch: 12\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/88 [00:01<02:00,  1.38s/it]"]},{"output_type":"stream","name":"stdout","text":["gen loss = 0.02768169902265072\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 88/88 [01:18<00:00,  1.12it/s]\n","100%|██████████| 38/38 [00:03<00:00, 11.01it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","=> Saving checkpoint\n","epoch: 13\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/88 [00:01<01:52,  1.30s/it]"]},{"output_type":"stream","name":"stdout","text":["gen loss = 0.04285845160484314\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 88/88 [01:18<00:00,  1.12it/s]\n","100%|██████████| 38/38 [00:03<00:00, 11.43it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","=> Saving checkpoint\n","epoch: 14\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/88 [00:01<01:59,  1.38s/it]"]},{"output_type":"stream","name":"stdout","text":["gen loss = 0.037633560597896576\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 88/88 [01:18<00:00,  1.12it/s]\n","100%|██████████| 38/38 [00:03<00:00, 11.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","=> Saving checkpoint\n","epoch: 15\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/88 [00:01<02:10,  1.50s/it]"]},{"output_type":"stream","name":"stdout","text":["gen loss = 0.04496350139379501\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 88/88 [01:19<00:00,  1.11it/s]\n","100%|██████████| 38/38 [00:03<00:00, 11.03it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","=> Saving checkpoint\n","epoch: 16\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/88 [00:01<02:03,  1.42s/it]"]},{"output_type":"stream","name":"stdout","text":["gen loss = 0.02991548366844654\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 88/88 [01:18<00:00,  1.12it/s]\n","100%|██████████| 38/38 [00:03<00:00, 11.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","=> Saving checkpoint\n","epoch: 17\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/88 [00:01<01:59,  1.37s/it]"]},{"output_type":"stream","name":"stdout","text":["gen loss = 0.027228128165006638\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 88/88 [01:18<00:00,  1.12it/s]\n","100%|██████████| 38/38 [00:03<00:00, 11.23it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","=> Saving checkpoint\n","epoch: 18\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/88 [00:01<02:08,  1.48s/it]"]},{"output_type":"stream","name":"stdout","text":["gen loss = 0.04060293734073639\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 88/88 [01:18<00:00,  1.11it/s]\n","100%|██████████| 38/38 [00:03<00:00, 11.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","=> Saving checkpoint\n","epoch: 19\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/88 [00:01<02:10,  1.50s/it]"]},{"output_type":"stream","name":"stdout","text":["gen loss = 0.024744028225541115\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 88/88 [01:19<00:00,  1.11it/s]\n","100%|██████████| 38/38 [00:03<00:00, 11.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","=> Saving checkpoint\n","epoch: 20\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/88 [00:01<02:06,  1.46s/it]"]},{"output_type":"stream","name":"stdout","text":["gen loss = 0.02770739048719406\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 88/88 [01:18<00:00,  1.11it/s]\n","100%|██████████| 38/38 [00:03<00:00, 11.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","=> Saving checkpoint\n","epoch: 21\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/88 [00:01<02:04,  1.43s/it]"]},{"output_type":"stream","name":"stdout","text":["gen loss = 0.030691787600517273\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 88/88 [01:18<00:00,  1.12it/s]\n","100%|██████████| 38/38 [00:03<00:00, 11.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","=> Saving checkpoint\n","epoch: 22\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/88 [00:01<01:56,  1.34s/it]"]},{"output_type":"stream","name":"stdout","text":["gen loss = 0.03286115080118179\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 88/88 [01:18<00:00,  1.12it/s]\n","100%|██████████| 38/38 [00:03<00:00, 11.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","=> Saving checkpoint\n","epoch: 23\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/88 [00:01<02:04,  1.43s/it]"]},{"output_type":"stream","name":"stdout","text":["gen loss = 0.034102510660886765\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 88/88 [01:18<00:00,  1.12it/s]\n","100%|██████████| 38/38 [00:03<00:00, 11.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","=> Saving checkpoint\n","epoch: 24\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/88 [00:01<02:04,  1.43s/it]"]},{"output_type":"stream","name":"stdout","text":["gen loss = 0.024277620017528534\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 88/88 [01:18<00:00,  1.12it/s]\n","100%|██████████| 38/38 [00:03<00:00, 11.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","=> Saving checkpoint\n","epoch: 25\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/88 [00:01<02:06,  1.46s/it]"]},{"output_type":"stream","name":"stdout","text":["gen loss = 0.028644364327192307\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 88/88 [01:18<00:00,  1.12it/s]\n","100%|██████████| 38/38 [00:03<00:00, 11.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","=> Saving checkpoint\n","epoch: 26\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/88 [00:01<02:04,  1.44s/it]"]},{"output_type":"stream","name":"stdout","text":["gen loss = 0.02637122943997383\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 88/88 [01:18<00:00,  1.11it/s]\n","100%|██████████| 38/38 [00:03<00:00, 11.43it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","=> Saving checkpoint\n","epoch: 27\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/88 [00:01<02:03,  1.42s/it]"]},{"output_type":"stream","name":"stdout","text":["gen loss = 0.03189624100923538\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 88/88 [01:18<00:00,  1.12it/s]\n","100%|██████████| 38/38 [00:03<00:00, 11.53it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","=> Saving checkpoint\n","epoch: 28\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/88 [00:01<01:57,  1.35s/it]"]},{"output_type":"stream","name":"stdout","text":["gen loss = 0.02959318459033966\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 88/88 [01:18<00:00,  1.12it/s]\n","100%|██████████| 38/38 [00:03<00:00, 11.76it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","=> Saving checkpoint\n","epoch: 29\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/88 [00:01<01:55,  1.33s/it]"]},{"output_type":"stream","name":"stdout","text":["gen loss = 0.02816954255104065\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 88/88 [01:18<00:00,  1.12it/s]\n","100%|██████████| 38/38 [00:03<00:00, 11.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","=> Saving checkpoint\n","epoch: 30\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/88 [00:01<02:10,  1.50s/it]"]},{"output_type":"stream","name":"stdout","text":["gen loss = 0.024743445217609406\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 88/88 [01:18<00:00,  1.11it/s]\n","100%|██████████| 38/38 [00:03<00:00, 11.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","=> Saving checkpoint\n","epoch: 31\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/88 [00:01<02:02,  1.41s/it]"]},{"output_type":"stream","name":"stdout","text":["gen loss = 0.026651067659258842\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 88/88 [01:18<00:00,  1.12it/s]\n","100%|██████████| 38/38 [00:03<00:00, 11.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","=> Saving checkpoint\n","epoch: 32\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/88 [00:01<02:06,  1.45s/it]"]},{"output_type":"stream","name":"stdout","text":["gen loss = 0.024382276460528374\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 88/88 [01:18<00:00,  1.11it/s]\n","100%|██████████| 38/38 [00:03<00:00, 11.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","=> Saving checkpoint\n","epoch: 33\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/88 [00:01<02:06,  1.45s/it]"]},{"output_type":"stream","name":"stdout","text":["gen loss = 0.0259441826492548\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 88/88 [01:18<00:00,  1.11it/s]\n","100%|██████████| 38/38 [00:03<00:00, 11.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","=> Saving checkpoint\n","epoch: 34\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/88 [00:01<02:09,  1.49s/it]"]},{"output_type":"stream","name":"stdout","text":["gen loss = 0.03128160536289215\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 88/88 [01:18<00:00,  1.11it/s]\n","100%|██████████| 38/38 [00:03<00:00, 11.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","=> Saving checkpoint\n","epoch: 35\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/88 [00:01<02:07,  1.46s/it]"]},{"output_type":"stream","name":"stdout","text":["gen loss = 0.022672224789857864\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 88/88 [01:19<00:00,  1.11it/s]\n","100%|██████████| 38/38 [00:03<00:00, 10.77it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","=> Saving checkpoint\n","epoch: 36\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/88 [00:01<02:12,  1.53s/it]"]},{"output_type":"stream","name":"stdout","text":["gen loss = 0.03218594193458557\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 88/88 [01:18<00:00,  1.12it/s]\n","100%|██████████| 38/38 [00:03<00:00, 11.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","=> Saving checkpoint\n","epoch: 37\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/88 [00:01<02:05,  1.44s/it]"]},{"output_type":"stream","name":"stdout","text":["gen loss = 0.025744719430804253\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 88/88 [01:18<00:00,  1.12it/s]\n","100%|██████████| 38/38 [00:03<00:00, 10.96it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","=> Saving checkpoint\n","epoch: 38\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/88 [00:01<01:54,  1.32s/it]"]},{"output_type":"stream","name":"stdout","text":["gen loss = 0.028409013524651527\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 88/88 [01:18<00:00,  1.12it/s]\n","100%|██████████| 38/38 [00:03<00:00, 10.91it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","=> Saving checkpoint\n","epoch: 39\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/88 [00:01<02:01,  1.40s/it]"]},{"output_type":"stream","name":"stdout","text":["gen loss = 0.02749508246779442\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 88/88 [01:18<00:00,  1.12it/s]\n","100%|██████████| 38/38 [00:03<00:00, 11.46it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","=> Saving checkpoint\n","epoch: 40\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/88 [00:01<02:05,  1.44s/it]"]},{"output_type":"stream","name":"stdout","text":["gen loss = 0.03205931559205055\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 88/88 [01:18<00:00,  1.11it/s]\n","100%|██████████| 38/38 [00:03<00:00, 11.47it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","=> Saving checkpoint\n","epoch: 41\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/88 [00:01<02:05,  1.44s/it]"]},{"output_type":"stream","name":"stdout","text":["gen loss = 0.02288161963224411\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 88/88 [01:18<00:00,  1.12it/s]\n","100%|██████████| 38/38 [00:03<00:00, 11.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","=> Saving checkpoint\n","epoch: 42\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/88 [00:01<02:05,  1.44s/it]"]},{"output_type":"stream","name":"stdout","text":["gen loss = 0.030010106042027473\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 88/88 [01:18<00:00,  1.12it/s]\n","100%|██████████| 38/38 [00:03<00:00, 11.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","=> Saving checkpoint\n","epoch: 43\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/88 [00:01<02:07,  1.47s/it]"]},{"output_type":"stream","name":"stdout","text":["gen loss = 0.03372744098305702\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 88/88 [01:18<00:00,  1.11it/s]\n","100%|██████████| 38/38 [00:03<00:00, 10.90it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","=> Saving checkpoint\n","epoch: 44\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/88 [00:01<01:52,  1.29s/it]"]},{"output_type":"stream","name":"stdout","text":["gen loss = 0.02419453300535679\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 88/88 [01:18<00:00,  1.12it/s]\n","100%|██████████| 38/38 [00:03<00:00, 11.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","=> Saving checkpoint\n","epoch: 45\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/88 [00:01<01:55,  1.33s/it]"]},{"output_type":"stream","name":"stdout","text":["gen loss = 0.026921477168798447\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 88/88 [01:18<00:00,  1.12it/s]\n","100%|██████████| 38/38 [00:03<00:00, 11.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","=> Saving checkpoint\n","epoch: 46\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/88 [00:01<02:02,  1.41s/it]"]},{"output_type":"stream","name":"stdout","text":["gen loss = 0.026375900954008102\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 88/88 [01:18<00:00,  1.12it/s]\n","100%|██████████| 38/38 [00:03<00:00, 11.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","=> Saving checkpoint\n","epoch: 47\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/88 [00:01<02:10,  1.50s/it]"]},{"output_type":"stream","name":"stdout","text":["gen loss = 0.02664848044514656\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 88/88 [01:18<00:00,  1.12it/s]\n","100%|██████████| 38/38 [00:03<00:00, 11.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","=> Saving checkpoint\n","epoch: 48\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/88 [00:01<02:06,  1.45s/it]"]},{"output_type":"stream","name":"stdout","text":["gen loss = 0.02368355542421341\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 88/88 [01:18<00:00,  1.12it/s]\n","100%|██████████| 38/38 [00:03<00:00, 11.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","=> Saving checkpoint\n","epoch: 49\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 1/88 [00:01<02:06,  1.45s/it]"]},{"output_type":"stream","name":"stdout","text":["gen loss = 0.02344530262053013\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 88/88 [01:17<00:00,  1.14it/s]\n","100%|██████████| 38/38 [00:03<00:00, 11.63it/s]\n"]},{"output_type":"stream","name":"stdout","text":["=> Saving checkpoint\n","=> Saving checkpoint\n","[tensor(0.0315, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(0.0336, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(0.0456, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(0.0328, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(0.0362, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(0.0244, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(0.0351, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(0.0356, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(0.0300, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(0.0315, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(0.0262, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(0.0261, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(0.0381, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(0.0273, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(0.0378, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(0.0282, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(0.0302, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(0.0247, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(0.0276, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(0.0276, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(0.0228, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(0.0251, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(0.0272, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(0.0223, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(0.0244, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(0.0249, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(0.0252, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(0.0279, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(0.0233, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(0.0228, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(0.0290, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(0.0223, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(0.0259, device='cuda:0', grad_fn=<MseLossBackward0>)]\n","test loss\n","[[...], [...], [...], [...], [...], [...], [...], [...], [...], [...], [...], [...], [...], [...], [...], [...], [...], [...], [...], [...], [...], [...], [...], [...], [...], [...], [...], [...], [...], [...], [...], [...], [...], [...], [...], [...], [...], [...], [...], [...], [...], [...], [...], [...], [...], [...], [...], [...], [...], [...]]\n"]}]},{"cell_type":"code","source":["dataset = MyImageFolder(root_dir=\"/content/drive/MyDrive/APS360/personal_bird_test_images/bird_pic224\")\n","loader = DataLoader(\n","dataset,\n","batch_size=BATCH_SIZE,\n","shuffle=True,\n","pin_memory=True,\n","num_workers=NUM_WORKERS,\n",")\n","gen = Generator(in_channels=3).to(DEVICE)\n","disc = Discriminator(in_channels=3).to(DEVICE)\n","opt_gen = optim.Adam(gen.parameters(), lr=LEARNING_RATE, betas=(0.9, 0.999))\n","opt_disc = optim.Adam(disc.parameters(), lr=LEARNING_RATE, betas=(0.9, 0.999))\n","mse = nn.MSELoss()\n","bce = nn.BCEWithLogitsLoss()\n","vgg_loss = VGGLoss()\n","\n","if LOAD_MODEL:\n","    load_checkpoint(\n","    CHECKPOINT_GEN,\n","    gen,\n","    opt_gen,\n","    LEARNING_RATE,\n","      )\n","    \n","    load_checkpoint(\n","      CHECKPOINT_DISC, disc, opt_disc, LEARNING_RATE,\n","      )\n","\n","\n"],"metadata":{"id":"eNEhwnVPCEO3","colab":{"base_uri":"https://localhost:8080/","height":156,"referenced_widgets":["d71dcb02691948419e06550fff4159fc","ee6833e6e3d441ee985873601972976a","b47689bf0d1b41bbb1f5c5fb5f84d318","1ba9da10310b442b9b32fe169c9d6e6b","f2342b9d0f3e421ba2d0a60fcecaee31","5e9ce6b466864c24a7db0c47ecb9e27c","31e52324ca0e4296be5ea097d347663f","22fcb7e9524341358829ad53664bb35a","2ab972cca66d475cb17332fd8a974af3","eb207f252f884f7c88f20a642177cdd6","b5b06ef308564df98867afbde3d7a114"]},"executionInfo":{"status":"ok","timestamp":1649095688209,"user_tz":240,"elapsed":22270,"user":{"displayName":"Daniel Rafique","userId":"02654504376856222239"}},"outputId":"7ff76434-171b-4949-c06f-ce156a73428c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0.00/548M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d71dcb02691948419e06550fff4159fc"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["=> Loading checkpoint\n","=> Loading checkpoint\n"]}]},{"cell_type":"code","source":["plot_examples(\"/content/drive/MyDrive/APS360/Bird_Data_LR_Test/\", gen)"],"metadata":{"id":"GCI_647TLTCn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#for demo\n","plot_examples(\"/content/drive/MyDrive/APS360/personal_bird_test_images/bird_pic224/pics/\", gen)"],"metadata":{"id":"zNG7J5uzlVQa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from albumentations.augmentations.transforms import Resize\n","import os\n","f = '/content/saved'\n","for file in os.listdir(f):\n","    f_img = f+\"/\"+file\n","    #print(file)\n","    if f_img != '/content/saved/.ipynb_checkpoints':\n","      img = Image.open(f_img)\n","      img = img.resize((224,224))\n","      img.save(f_img)"],"metadata":{"id":"bYilbufmTRYG"},"execution_count":null,"outputs":[]}]}